{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e30ac2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from utils.show import show_layers_from_mask, show_layers_from_boundary\n",
    "\n",
    "                        \n",
    "def boundary_length_distribution(folder):\n",
    "    lengths = []\n",
    "    for file in folder:\n",
    "        data = loadmat(file)\n",
    "        for bscan in data[\"layerMaps\"]:\n",
    "            x_inds, _ = np.where(~np.isnan(bscan))\n",
    "            if x_inds.any():\n",
    "                lengths.append(x_inds[-1] - x_inds[0])\n",
    "    return lengths\n",
    "\n",
    "\n",
    "def boundary_middle_distribution(folder):\n",
    "    middles = []\n",
    "    for file in folder:\n",
    "        data = loadmat(file)\n",
    "        for bscan in data[\"layerMaps\"]:\n",
    "            x_inds, _ = np.where(~np.isnan(bscan))\n",
    "            if x_inds.any():\n",
    "                middles.append(x_inds[len(x_inds) // 2])\n",
    "    return middles\n",
    "\n",
    "\n",
    "\n",
    "def create_patches(img, lyr, patch_width):\n",
    "    idx = np.where((np.isnan(lyr)).any(axis=0))[0]\n",
    "    diff = np.diff(idx)\n",
    "    useful_parts = diff >= patch_width\n",
    "    useful_lengths = diff[useful_parts]\n",
    "    useful_start_idx = idx[np.pad(useful_parts, (0, 1), constant_values=[False])]\n",
    "    for ustart, ulength in zip(useful_start_idx, useful_lengths):\n",
    "        number_of_shifts = (ulength - 1) // patch_width\n",
    "        for shift_idx in range(number_of_shifts):\n",
    "            img_patch = img[:, ustart + 1 + shift_idx * patch_width:ustart + 1 + (shift_idx + 1) * patch_width]\n",
    "            lyr_patch = lyr[:, ustart + 1 + shift_idx * patch_width:ustart + 1 + (shift_idx + 1) * patch_width]\n",
    "            mask = create_layer_mask(lyr_patch, img_patch.shape[0])\n",
    "            yield img_patch, mask\n",
    "            \n",
    "def generate_dme_dataset(input_dir, output_dir, patch_width):\n",
    "    files = list(Path(input_dir).glob(\"*\"))\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir()\n",
    "    cnt = 0\n",
    "    for file in tqdm(files, desc=\"data generation\"):\n",
    "        data = loadmat(file)\n",
    "        layers = data[\"manualLayers1\"].transpose((2, 0, 1))\n",
    "        images = data[\"images\"].transpose((2, 0, 1))\n",
    "        for idx, (image, layer) in enumerate(zip(images, layers)):\n",
    "            patch_generator = create_patches(image, layer, patch_width)\n",
    "            for img, mask in patch_generator:\n",
    "                Image.fromarray(img).save(output_dir / f\"img_{cnt}.png\")\n",
    "                Image.fromarray(mask).save(output_dir / f\"mask_{cnt}.png\")\n",
    "                cnt += 1\n",
    "                \n",
    "def create_boundary_mask(boundary_array, height):\n",
    "    mask = np.zeros((height, boundary_array.shape[1]), dtype=\"uint8\")\n",
    "    for col_idx, col in enumerate(boundary_array.T):\n",
    "        if ~np.isnan(col).any():\n",
    "            for boundary in col:\n",
    "                mask[int(boundary), col_idx] = 1\n",
    "    return mask\n",
    "\n",
    "def create_layer_mask(boundary_array, height, fluid=None):\n",
    "    mask = np.zeros((height, boundary_array.shape[1]), dtype=\"uint8\")\n",
    "    for col_idx, col in enumerate(boundary_array.T):\n",
    "        prev_boundary = 0\n",
    "        for boundary_idx, boundary in enumerate(col):\n",
    "            mask[prev_boundary:int(boundary) + 1, col_idx] = boundary_idx\n",
    "            prev_boundary = int(boundary) + 1\n",
    "        mask[prev_boundary:, col_idx] = boundary_idx + 1\n",
    "    fluid_class = len(col) + 1\n",
    "    if isinstance(fluid, np.ndarray):\n",
    "        mask[fluid != 0] = fluid_class\n",
    "    return mask\n",
    "\n",
    "def create_patches(img, lyr, patch_width, fluid):\n",
    "    idx = np.where((np.isnan(lyr)).any(axis=0))[0]\n",
    "    diff = np.diff(idx)\n",
    "    useful_parts = diff >= patch_width\n",
    "    useful_lengths = diff[useful_parts]\n",
    "    useful_start_idx = idx[np.pad(useful_parts, (0, 1), constant_values=[False])]\n",
    "    for ustart, ulength in zip(useful_start_idx, useful_lengths):\n",
    "        number_of_shifts = (ulength - 1) // patch_width\n",
    "        for shift_idx in range(number_of_shifts):\n",
    "            indices = (slice(None), slice(\n",
    "                ustart + 1 + shift_idx * patch_width, ustart + 1 + (shift_idx + 1) * patch_width\n",
    "            ))\n",
    "            img_patch = img[indices]\n",
    "            lyr_patch = lyr[indices]\n",
    "            fluid_patch = fluid[indices] if isinstance(fluid, np.ndarray) else fluid\n",
    "            mask = create_layer_mask(lyr_patch, img_patch.shape[0], fluid_patch)\n",
    "            yield img_patch, mask, lyr_patch.T.tolist()\n",
    "            \n",
    "def generate_dme_dataset(input_dir, output_dir, patch_width, use_fluid=False):\n",
    "    files = list(Path(input_dir).glob(\"*\"))\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir()\n",
    "    cnt = 0\n",
    "    boundary_indices_dict = {}\n",
    "    layer_widths_dict = {}\n",
    "    for file in tqdm(files, desc=\"data generation\"):\n",
    "        data = loadmat(file)\n",
    "        layers = data[\"manualLayers1\"].transpose((2, 0, 1))\n",
    "        images = data[\"images\"].transpose((2, 0, 1))\n",
    "        fluids = data[\"manualFluid1\"].transpose((2, 0, 1))\n",
    "        for idx, (image, layer, fluid) in enumerate(zip(images, layers, fluids)):\n",
    "            fluid = fluid if (~np.isnan(fluid)).any() and use_fluid else None \n",
    "            patch_generator = create_patches(image, layer, patch_width, fluid)\n",
    "            for img, mask, boundary_indices_list in patch_generator:\n",
    "                Image.fromarray(img).save(output_dir / f\"img_{cnt}.png\")\n",
    "                Image.fromarray(mask).save(output_dir / f\"mask_{cnt}.png\")\n",
    "                boundary_indices_dict[cnt] = boundary_indices_list\n",
    "                cnt += 1\n",
    "    with open(output_dir / \"boundary_indices.json\", \"w\") as boundary_file:\n",
    "        json.dump(boundary_indices_dict, boundary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39dfa2b",
   "metadata": {},
   "source": [
    "# LOAD FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321e1e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "amd = list(Path(\"../../dataset/raw/AMD/\").glob(\"*\"))\n",
    "control = list(Path(\"../../dataset/raw/Control/\").glob(\"*\"))\n",
    "dme = list(Path(\"../../dataset/raw/2015_BOE_Chiu/\").glob(\"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c56772",
   "metadata": {},
   "source": [
    "# DME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54d4eacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../../dataset/raw/2015_BOE_Chiu/Subject_02.mat'),\n",
       " PosixPath('../../dataset/raw/2015_BOE_Chiu/Subject_04.mat'),\n",
       " PosixPath('../../dataset/raw/2015_BOE_Chiu/Subject_01.mat'),\n",
       " PosixPath('../../dataset/raw/2015_BOE_Chiu/Subject_08.mat'),\n",
       " PosixPath('../../dataset/raw/2015_BOE_Chiu/Subject_06.mat'),\n",
       " PosixPath('../../dataset/raw/2015_BOE_Chiu/Subject_09.mat'),\n",
       " PosixPath('../../dataset/raw/2015_BOE_Chiu/Subject_07.mat'),\n",
       " PosixPath('../../dataset/raw/2015_BOE_Chiu/Subject_03.mat'),\n",
       " PosixPath('../../dataset/raw/2015_BOE_Chiu/Subject_05.mat'),\n",
       " PosixPath('../../dataset/raw/2015_BOE_Chiu/Subject_10.mat')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e22a058a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 15, 20, 25, 28, 30, 32, 35, 40, 45, 50])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadmat(dme[-1])\n",
    "np.where((~np.isnan(data[\"manualLayers1\"])).any(axis=(0, 1)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1f1d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 30\n",
    "idx = 32\n",
    "img = data[\"images\"][..., idx]\n",
    "lyr1 = data[\"manualLayers1\"][..., idx]\n",
    "lyr2 = data[\"manualLayers2\"][..., idx]\n",
    "fluid1 = data[\"manualFluid1\"][..., idx]\n",
    "fluid2 = data[\"manualFluid2\"][..., idx]\n",
    "\n",
    "Image.fromarray(img).show()\n",
    "# show_layers_from_boundary(img, lyr).show()\n",
    "show_layers_from_boundary(img, lyr, fluid=fluid1).show()\n",
    "show_layers_from_boundary(img, lyr2, fluid=fluid2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a139cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 12\n",
    "img = np.array(Image.open(f\"../../generated/DME_496/img_{idx}.png\"))\n",
    "lyr = np.array(Image.open(f\"../../generated/DME_496/mask_{idx}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd24846",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_mask_array(img, lyr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3882a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_boundary_array(img, lyr2.T).show()\n",
    "show_layers_from_boundary_array(img, lyr.T).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "c1bd611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(\"../../dataset/raw/2015_BOE_Chiu/Subject_02.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "4fdaf9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "9bbd9e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data[\"images\"][..., idx]\n",
    "lyr = data[\"manualLayers1\"][..., idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "de026b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_boundary_array(img, lyr.T).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e553de24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(523, 523): 33,\n",
       "         (547, 547): 11,\n",
       "         (535, 535): 11,\n",
       "         (541, 541): 33,\n",
       "         (505, 505): 11,\n",
       "         (499, 499): 11})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmented_length = list()\n",
    "\n",
    "for d in range(10):\n",
    "    data = loadmat(dme[d])\n",
    "    for lyr_ind in range(61):\n",
    "        m1 = data[\"manualLayers1\"][..., lyr_ind]\n",
    "        m2 = data[\"manualLayers2\"][..., lyr_ind]\n",
    "        lengths = [] \n",
    "        if (~np.isnan(m1)).any():\n",
    "            w_idx = np.where(~np.isnan(m1))[1]\n",
    "            delta = w_idx[-1] - w_idx[0]\n",
    "            lengths.append(delta)\n",
    "        else:\n",
    "            lengths.append(0)\n",
    "        if (~np.isnan(m2)).any():\n",
    "            w_idx = np.where(~np.isnan(m2))[1]\n",
    "            delta = w_idx[-1] - w_idx[0]\n",
    "            lengths.append(delta)\n",
    "        else:\n",
    "            lengths.append(0)\n",
    "        if sum(lengths):\n",
    "            segmented_length.append(tuple(lengths))\n",
    "            \n",
    "Counter(segmented_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2861ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dme496img = sorted(list(Path(\"../../generated/DME_496/\").glob(\"img*\")))\n",
    "dme496mask = sorted(list(Path(\"../../generated/DME_496\").glob(\"mask*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ed8e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open(dme496img[0]))\n",
    "mask = np.array(Image.open(dme496mask[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dee6862",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_mask_array(img, mask).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d61f68d",
   "metadata": {},
   "source": [
    "# There are parts where not all the layers are annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9bb78f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0, 127,   0,   0,   0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for d in range(10):\n",
    "#     data = loadmat(dme[d])\n",
    "#     lyr = data[\"manualLayers1\"]\n",
    "#     if (np.isnan(lyr).any(axis=0) != np.isnan(lyr).all(axis=0)).sum():\n",
    "#         print(d)\n",
    "\n",
    "data = loadmat(dme[0])\n",
    "lyr = data[\"manualLayers1\"]\n",
    "img = data[\"images\"]\n",
    "idx = (np.isnan(lyr).any(axis=0) != np.isnan(lyr).all(axis=0))\n",
    "np.isnan(lyr[:, idx]).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57253cc0",
   "metadata": {},
   "source": [
    "# Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c966cb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data generation: 100%|██████████| 5/5 [00:09<00:00,  1.99s/it]\n",
      "data generation: 100%|██████████| 5/5 [00:09<00:00,  1.91s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_width = 128\n",
    "fluid = True\n",
    "generate_dme_dataset(\"../../dataset/raw/1-5\", f\"../../generated{'/fluid' if fluid else ''}/training/DME_{patch_width}\", patch_width, use_fluid=True)\n",
    "generate_dme_dataset(\"../../dataset/raw/6-10\", f\"../../generated{'/fluid' if fluid else ''}/validation/DME_{patch_width}\", patch_width, use_fluid=True)\n",
    "len(list(Path(f\"../../generated{'/fluid' if fluid else ''}/training/DME_{patch_width}\").glob(\"img*\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d0aa22",
   "metadata": {},
   "source": [
    "# Proove that the layer mask generation is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "eea09a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmask = create_boundary_mask(lyr[:, 500:600], 496)\n",
    "lmask = create_layer_mask(lyr[:, 500:600], 496)\n",
    "diff = np.diff(lmask, axis=0)\n",
    "(np.pad(diff, ((0, 1), (0, 0)), constant_values=(0,)) != bmask).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df366ab",
   "metadata": {},
   "source": [
    "# AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79804753",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(amd[0])\n",
    "idx = 30\n",
    "img = data[\"images\"][:, :, idx]\n",
    "lyr = data[\"layerMaps\"][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db9b6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_amd_dataset(amd_dir, control_dir, output_dir, patch_width):\n",
    "    files = list(\n",
    "        chain(\n",
    "            Path(amd_dir).glob(\"*\"),\n",
    "            Path(control_dir).glob(\"*\")\n",
    "        )\n",
    "    )\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir()\n",
    "    cnt = 0\n",
    "    for file in tqdm(files, desc=\"data generation\"):\n",
    "        data = loadmat(file)\n",
    "        layers = data[\"layerMaps\"].transpose((0, 2, 1))\n",
    "        images = data[\"images\"].transpose((2, 0, 1))\n",
    "        for idx, (image, layer) in enumerate(zip(images, layers)):\n",
    "            patch_generator = create_patches(image, layer, patch_width)\n",
    "            for img, mask in patch_generator:\n",
    "                Image.fromarray(img).save(output_dir / f\"img_{cnt}.png\")\n",
    "                Image.fromarray(mask).save(output_dir / f\"mask_{cnt}.png\")\n",
    "                cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e3bc761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data generation: 100%|██████████| 384/384 [04:31<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "patch_width = 736\n",
    "generate_amd_dataset(\n",
    "    \"../../dataset/raw/AMD/\",\n",
    "    \"../../dataset/raw/Control/\",\n",
    "    f\"../../generated/AMD_{patch_width}\",\n",
    "    patch_width\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbcd0e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2901"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(Path(\"../../generated/AMD_736\").glob(\"img*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45500735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadmat(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88932bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "736 / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccbf9efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_boundary_array(img, lyr).show()\n",
    "show_boundary_from_boundary_array(img, lyr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80338d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
