{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac5f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import json\n",
    "\n",
    "from utils.show import show_layers_from_mask, show_layers_from_boundary\n",
    "\n",
    "                        \n",
    "def boundary_length_distribution(folder):\n",
    "    lengths = []\n",
    "    for file in folder:\n",
    "        data = loadmat(file)\n",
    "        for bscan in data[\"layerMaps\"]:\n",
    "            x_inds, _ = np.where(~np.isnan(bscan))\n",
    "            if x_inds.any():\n",
    "                lengths.append(x_inds[-1] - x_inds[0])\n",
    "    return lengths\n",
    "\n",
    "\n",
    "def boundary_middle_distribution(folder):\n",
    "    middles = []\n",
    "    for file in folder:\n",
    "        data = loadmat(file)\n",
    "        for bscan in data[\"layerMaps\"]:\n",
    "            x_inds, _ = np.where(~np.isnan(bscan))\n",
    "            if x_inds.any():\n",
    "                middles.append(x_inds[len(x_inds) // 2])\n",
    "    return middles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a825337",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "581f8d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(img, lyr, patch_width):\n",
    "    idx = np.where((np.isnan(lyr)).any(axis=0))[0]\n",
    "    diff = np.diff(idx)\n",
    "    useful_parts = diff >= patch_width\n",
    "    useful_lengths = diff[useful_parts]\n",
    "    useful_start_idx = idx[np.pad(useful_parts, (0, 1), constant_values=[False])]\n",
    "    for ustart, ulength in zip(useful_start_idx, useful_lengths):\n",
    "        number_of_shifts = (ulength - 1) // patch_width\n",
    "        for shift_idx in range(number_of_shifts):\n",
    "            img_patch = img[:, ustart + 1 + shift_idx * patch_width:ustart + 1 + (shift_idx + 1) * patch_width]\n",
    "            lyr_patch = lyr[:, ustart + 1 + shift_idx * patch_width:ustart + 1 + (shift_idx + 1) * patch_width]\n",
    "            mask = create_layer_mask(lyr_patch, img_patch.shape[0])\n",
    "            yield img_patch, mask\n",
    "            \n",
    "def generate_dme_dataset(input_dir, output_dir, patch_width):\n",
    "    files = list(Path(input_dir).glob(\"*\"))\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir()\n",
    "    cnt = 0\n",
    "    for file in tqdm(files, desc=\"data generation\"):\n",
    "        data = loadmat(file)\n",
    "        layers = data[\"manualLayers1\"].transpose((2, 0, 1))\n",
    "        images = data[\"images\"].transpose((2, 0, 1))\n",
    "        for idx, (image, layer) in enumerate(zip(images, layers)):\n",
    "            patch_generator = create_patches(image, layer, patch_width)\n",
    "            for img, mask in patch_generator:\n",
    "                Image.fromarray(img).save(output_dir / f\"img_{cnt}.png\")\n",
    "                Image.fromarray(mask).save(output_dir / f\"mask_{cnt}.png\")\n",
    "                cnt += 1\n",
    "                \n",
    "def create_boundary_mask(boundary_array, height):\n",
    "    mask = np.zeros((height, boundary_array.shape[1]), dtype=\"uint8\")\n",
    "    for col_idx, col in enumerate(boundary_array.T):\n",
    "        if ~np.isnan(col).any():\n",
    "            for boundary in col:\n",
    "                mask[int(boundary), col_idx] = 1\n",
    "    return mask\n",
    "\n",
    "def create_layer_mask(boundary_array, height, fluid=None):\n",
    "    mask = np.zeros((height, boundary_array.shape[1]), dtype=\"uint8\")\n",
    "    for col_idx, col in enumerate(boundary_array.T):\n",
    "        prev_boundary = 0\n",
    "        for boundary_idx, boundary in enumerate(col):\n",
    "            mask[prev_boundary:int(boundary) + 1, col_idx] = boundary_idx\n",
    "            prev_boundary = int(boundary) + 1\n",
    "        mask[prev_boundary:, col_idx] = boundary_idx + 1\n",
    "    fluid_class = len(col) + 1\n",
    "    if isinstance(fluid, np.ndarray):\n",
    "        mask[fluid != 0] = fluid_class\n",
    "    return mask\n",
    "\n",
    "def create_patches(img, lyr, patch_width, fluid):\n",
    "    idx = np.where((np.isnan(lyr)).any(axis=0))[0]\n",
    "    diff = np.diff(idx)\n",
    "    useful_parts = diff >= patch_width\n",
    "    useful_lengths = diff[useful_parts]\n",
    "    useful_start_idx = idx[np.pad(useful_parts, (0, 1), constant_values=[False])]\n",
    "    for ustart, ulength in zip(useful_start_idx, useful_lengths):\n",
    "        number_of_shifts = (ulength - 1) // patch_width\n",
    "        for shift_idx in range(number_of_shifts):\n",
    "            indices = (slice(None), slice(\n",
    "                ustart + 1 + shift_idx * patch_width, ustart + 1 + (shift_idx + 1) * patch_width\n",
    "            ))\n",
    "            img_patch = img[indices]\n",
    "            lyr_patch = lyr[indices]\n",
    "            fluid_patch = fluid[indices] if isinstance(fluid, np.ndarray) else fluid\n",
    "            mask = create_layer_mask(lyr_patch, img_patch.shape[0], fluid_patch)\n",
    "            yield img_patch, mask, lyr_patch.T.tolist()\n",
    "            \n",
    "def generate_dme_dataset(input_dir, output_dir, patch_width, use_fluid=False):\n",
    "    files = list(Path(input_dir).glob(\"*\"))\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir()\n",
    "    cnt = 0\n",
    "    boundary_indices_dict = {}\n",
    "    layer_widths_dict = {}\n",
    "    for file in tqdm(files, desc=\"data generation\"):\n",
    "        data = loadmat(file)\n",
    "        layers = data[\"manualLayers1\"].transpose((2, 0, 1))\n",
    "        images = data[\"images\"].transpose((2, 0, 1))\n",
    "        fluids = data[\"manualFluid1\"].transpose((2, 0, 1))\n",
    "        for idx, (image, layer, fluid) in enumerate(zip(images, layers, fluids)):\n",
    "            fluid = fluid if (~np.isnan(fluid)).any() and use_fluid else None \n",
    "            patch_generator = create_patches(image, layer, patch_width, fluid)\n",
    "            for img, mask, boundary_indices_list in patch_generator:\n",
    "                Image.fromarray(img).save(output_dir / f\"img_{cnt}.png\")\n",
    "                Image.fromarray(mask).save(output_dir / f\"mask_{cnt}.png\")\n",
    "                boundary_indices_dict[cnt] = boundary_indices_list\n",
    "                cnt += 1\n",
    "    with open(output_dir / \"boundary_indices.json\", \"w\") as boundary_file:\n",
    "        json.dump(boundary_indices_dict, boundary_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5963a",
   "metadata": {},
   "source": [
    "# LOAD FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a662a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "amd = list(Path(\"../../dataset/raw/AMD/\").glob(\"*\"))\n",
    "control = list(Path(\"../../dataset/raw/Control/\").glob(\"*\"))\n",
    "dme = list(Path(\"../../dataset/raw/2015_BOE_Chiu/\").glob(\"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9879d38",
   "metadata": {},
   "source": [
    "# Test new concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3c4cbb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 0, -1, 0, 1, 0, -1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c100b288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x) - x.flip(0).min(0).indices - 1 - x.max(0).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1181dc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.30493972, -1.38685806, -0.25046206, -1.66599754,  0.90199246,\n",
       "        -0.27416333, -0.62988202, -0.68810881, -0.88376661,  0.36708645],\n",
       "       [ 0.3900947 , -0.74614864, -0.24758149,  0.44142163,  0.00417762,\n",
       "         0.38001564, -0.5956527 ,  0.57951245,  1.44324228,  0.51722583]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[(slice(1, 3), slice(None))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eaaf2c",
   "metadata": {},
   "source": [
    "# DME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72327faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(dme[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0530841c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10, 15, 20, 25, 28, 30, 32, 35, 40, 45, 50]),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((~np.isnan(data[\"manualFluid1\"])).any(axis=(0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "02c6ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "img = data[\"images\"][..., idx]\n",
    "lyr = data[\"manualLayers1\"][..., idx]\n",
    "fluid = data[\"manualFluid1\"][..., idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "612e614f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1a74f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_layers_from_boundary(img_array, layer_array, mean_std=None, a_scan_length=496, fluid=None, normed=False):\n",
    "    err_msg = \"layer boundaries not compatible with image width\"\n",
    "    assert img_array.shape[1] == layer_array.shape[1], err_msg\n",
    "    if type(img_array) == torch.Tensor:\n",
    "        img_array = img_array.numpy()\n",
    "    if type(layer_array) == torch.Tensor:\n",
    "        layer_array = layer_array.numpy()\n",
    "    if mean_std:\n",
    "        img_array = img_array * mean_std[1] + mean_std[0]\n",
    "        layer_array = layer_array * mean_std[3] + mean_std[2]\n",
    "    if normed:\n",
    "        img_array = np.asarray(img_array * 255, \"uint8\")\n",
    "        layer_array = np.asarray(layer_array * a_scan_length, \"uint8\")\n",
    "    dme_colorcode = {\n",
    "        1: (170, 160, 250),\n",
    "        2: (120, 200, 250),\n",
    "        3: (80, 200, 250),\n",
    "        4: (50, 230, 250),\n",
    "        5: (20, 230, 250),\n",
    "        6: (0, 230, 250),\n",
    "        7: (0, 230, 100),\n",
    "        8: (180, 255, 255)  # fluid\n",
    "    }\n",
    "    amd_colorcode = {\n",
    "        1: (180, 200, 250),\n",
    "        2: (120, 200, 250),\n",
    "    }\n",
    "    zeros = np.zeros_like(img_array, dtype=\"uint8\")\n",
    "    hue = np.zeros_like(img_array, dtype=\"uint8\")\n",
    "    saturation = np.zeros_like(img_array, dtype=\"uint8\")\n",
    "    value = np.zeros_like(img_array, dtype=\"uint8\")\n",
    "    mask = np.zeros(img_array.shape, dtype=\"uint8\")\n",
    "    layer_array = layer_array.T\n",
    "    for w in range(img_array.shape[1]):\n",
    "        if ~np.isnan(layer_array[w, :]).any():\n",
    "            last_boundary = int(layer_array[w, 0])\n",
    "            for idx, h in enumerate(layer_array[w, 1:]):\n",
    "                curr_boundary = int(h) + 1\n",
    "                mask[last_boundary:curr_boundary, w] = idx + 1\n",
    "                last_boundary = curr_boundary\n",
    "    if fluid is not None:\n",
    "        mask[fluid != 0] = 8\n",
    "    if layer_array.shape[1] == 8:\n",
    "        for klass, hsv in dme_colorcode.items():\n",
    "            hue[mask == klass] = hsv[0]\n",
    "            saturation[mask == klass] = hsv[1]\n",
    "            value[mask == klass] = hsv[2]\n",
    "    if layer_array.shape[1] == 3:\n",
    "        for klass, hsv in amd_colorcode.items():\n",
    "            hue[mask == klass] = hsv[0]\n",
    "            saturation[mask == klass] = hsv[1]\n",
    "            value[mask == klass] = hsv[2]\n",
    "    alpha = np.zeros_like(img_array, dtype=\"uint8\")\n",
    "    alpha[mask != 0] = 255\n",
    "    img_stack = np.array([zeros, zeros, img_array]).transpose((1, 2, 0))\n",
    "    img = Image.fromarray(img_stack, mode=\"HSV\")\n",
    "    colored_mask_stack = np.array([hue, saturation, value]).transpose((1, 2, 0))\n",
    "    colored_mask = Image.fromarray(colored_mask_stack, mode=\"HSV\")\n",
    "    alphaimg = Image.fromarray(alpha)\n",
    "    img_with_boundaries = Image.composite(colored_mask, img, alphaimg)\n",
    "    return img_with_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "59f90016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.data import OCTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7b75ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_boundary(img, lyr, normed=False, fluid=fluid).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "39a5e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = OCTDataset(\"../../generated/fluid/training/DME_64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c4b5e52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "25\n",
      "26\n",
      "32\n",
      "33\n",
      "38\n",
      "39\n",
      "44\n",
      "45\n",
      "58\n",
      "59\n",
      "66\n",
      "67\n",
      "73\n",
      "74\n",
      "75\n",
      "93\n",
      "96\n",
      "99\n",
      "100\n",
      "104\n",
      "109\n",
      "112\n",
      "113\n",
      "116\n",
      "117\n",
      "118\n",
      "129\n",
      "130\n",
      "137\n",
      "138\n",
      "151\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "163\n",
      "167\n",
      "170\n",
      "173\n",
      "174\n",
      "179\n",
      "180\n",
      "218\n",
      "224\n",
      "244\n",
      "282\n",
      "283\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "294\n",
      "295\n",
      "296\n",
      "299\n",
      "300\n",
      "302\n",
      "307\n",
      "311\n",
      "317\n",
      "318\n",
      "323\n",
      "324\n",
      "325\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ds)):\n",
    "    x, y = ds[i]\n",
    "    if y.max() == 9:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83751670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f5cd0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 317\n",
    "show_layers_from_mask(ds[idx][0], ds[idx][1], normed=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "980ee956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 768, 61)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"manualFluid1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffd548fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([np.nan, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d59425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 12\n",
    "img = np.array(Image.open(f\"../../generated/DME_496/img_{idx}.png\"))\n",
    "lyr = np.array(Image.open(f\"../../generated/DME_496/mask_{idx}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae94f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_mask_array(img, lyr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ba13431",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_boundary_array(img, lyr2.T).show()\n",
    "show_layers_from_boundary_array(img, lyr.T).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "5066d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(\"../../dataset/raw/2015_BOE_Chiu/Subject_02.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "83ba2c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "fa2073d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data[\"images\"][..., idx]\n",
    "lyr = data[\"manualLayers1\"][..., idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "c63f2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_boundary_array(img, lyr.T).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8274aba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(523, 523): 33,\n",
       "         (547, 547): 11,\n",
       "         (535, 535): 11,\n",
       "         (541, 541): 33,\n",
       "         (505, 505): 11,\n",
       "         (499, 499): 11})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmented_length = list()\n",
    "\n",
    "for d in range(10):\n",
    "    data = loadmat(dme[d])\n",
    "    for lyr_ind in range(61):\n",
    "        m1 = data[\"manualLayers1\"][..., lyr_ind]\n",
    "        m2 = data[\"manualLayers2\"][..., lyr_ind]\n",
    "        lengths = [] \n",
    "        if (~np.isnan(m1)).any():\n",
    "            w_idx = np.where(~np.isnan(m1))[1]\n",
    "            delta = w_idx[-1] - w_idx[0]\n",
    "            lengths.append(delta)\n",
    "        else:\n",
    "            lengths.append(0)\n",
    "        if (~np.isnan(m2)).any():\n",
    "            w_idx = np.where(~np.isnan(m2))[1]\n",
    "            delta = w_idx[-1] - w_idx[0]\n",
    "            lengths.append(delta)\n",
    "        else:\n",
    "            lengths.append(0)\n",
    "        if sum(lengths):\n",
    "            segmented_length.append(tuple(lengths))\n",
    "            \n",
    "Counter(segmented_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f32ef2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dme496img = sorted(list(Path(\"../../generated/DME_496/\").glob(\"img*\")))\n",
    "dme496mask = sorted(list(Path(\"../../generated/DME_496\").glob(\"mask*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfc7c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open(dme496img[0]))\n",
    "mask = np.array(Image.open(dme496mask[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e9e3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_mask_array(img, mask).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1bd1ff",
   "metadata": {},
   "source": [
    "# There are parts where not all the layers are annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb9798a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0, 127,   0,   0,   0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for d in range(10):\n",
    "#     data = loadmat(dme[d])\n",
    "#     lyr = data[\"manualLayers1\"]\n",
    "#     if (np.isnan(lyr).any(axis=0) != np.isnan(lyr).all(axis=0)).sum():\n",
    "#         print(d)\n",
    "\n",
    "data = loadmat(dme[0])\n",
    "lyr = data[\"manualLayers1\"]\n",
    "img = data[\"images\"]\n",
    "idx = (np.isnan(lyr).any(axis=0) != np.isnan(lyr).all(axis=0))\n",
    "np.isnan(lyr[:, idx]).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bdaec",
   "metadata": {},
   "source": [
    "# Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "45a43e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data generation: 100%|██████████| 5/5 [00:09<00:00,  1.88s/it]\n",
      "data generation: 100%|██████████| 5/5 [00:10<00:00,  2.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "682"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_width = 64\n",
    "fluid = True\n",
    "generate_dme_dataset(\"../../dataset/raw/1-5\", f\"../../generated{'/fluid' if fluid else ''}/training/DME_{patch_width}\", patch_width, use_fluid=True)\n",
    "generate_dme_dataset(\"../../dataset/raw/6-10\", f\"../../generated{'/fluid' if fluid else ''}/validation/DME_{patch_width}\", patch_width, use_fluid=True)\n",
    "len(list(Path(f\"../../generated/DME_{patch_width}\").glob(\"img*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7743cc72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-5818b236ffdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "a = np.array([M, None])\n",
    "b = a if a == None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17563394",
   "metadata": {},
   "source": [
    "# Proove that the layer mask generation is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f582fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmask = create_boundary_mask(lyr[:, 500:600], 496)\n",
    "lmask = create_layer_mask(lyr[:, 500:600], 496)\n",
    "diff = np.diff(lmask, axis=0)\n",
    "(np.pad(diff, ((0, 1), (0, 0)), constant_values=(0,)) != bmask).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5058cc5c",
   "metadata": {},
   "source": [
    "# AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "807eb96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(amd[0])\n",
    "idx = 30\n",
    "img = data[\"images\"][:, :, idx]\n",
    "lyr = data[\"layerMaps\"][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e28fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_amd_dataset(amd_dir, control_dir, output_dir, patch_width):\n",
    "    files = list(\n",
    "        chain(\n",
    "            Path(amd_dir).glob(\"*\"),\n",
    "            Path(control_dir).glob(\"*\")\n",
    "        )\n",
    "    )\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir()\n",
    "    cnt = 0\n",
    "    for file in tqdm(files, desc=\"data generation\"):\n",
    "        data = loadmat(file)\n",
    "        layers = data[\"layerMaps\"].transpose((0, 2, 1))\n",
    "        images = data[\"images\"].transpose((2, 0, 1))\n",
    "        for idx, (image, layer) in enumerate(zip(images, layers)):\n",
    "            patch_generator = create_patches(image, layer, patch_width)\n",
    "            for img, mask in patch_generator:\n",
    "                Image.fromarray(img).save(output_dir / f\"img_{cnt}.png\")\n",
    "                Image.fromarray(mask).save(output_dir / f\"mask_{cnt}.png\")\n",
    "                cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd5c6e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data generation: 100%|██████████| 384/384 [04:31<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "patch_width = 736\n",
    "generate_amd_dataset(\n",
    "    \"../../dataset/raw/AMD/\",\n",
    "    \"../../dataset/raw/Control/\",\n",
    "    f\"../../generated/AMD_{patch_width}\",\n",
    "    patch_width\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "934a9d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2901"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(Path(\"../../generated/AMD_736\").glob(\"img*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe63da7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadmat(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65be6f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "736 / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33fd3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_boundary_array(img, lyr).show()\n",
    "show_boundary_from_boundary_array(img, lyr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b58fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
