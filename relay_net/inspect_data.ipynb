{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9430f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import json\n",
    "\n",
    "                        \n",
    "def boundary_length_distribution(folder):\n",
    "    lengths = []\n",
    "    for file in folder:\n",
    "        data = loadmat(file)\n",
    "        for bscan in data[\"layerMaps\"]:\n",
    "            x_inds, _ = np.where(~np.isnan(bscan))\n",
    "            if x_inds.any():\n",
    "                lengths.append(x_inds[-1] - x_inds[0])\n",
    "    return lengths\n",
    "\n",
    "\n",
    "def boundary_middle_distribution(folder):\n",
    "    middles = []\n",
    "    for file in folder:\n",
    "        data = loadmat(file)\n",
    "        for bscan in data[\"layerMaps\"]:\n",
    "            x_inds, _ = np.where(~np.isnan(bscan))\n",
    "            if x_inds.any():\n",
    "                middles.append(x_inds[len(x_inds) // 2])\n",
    "    return middles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c086b80",
   "metadata": {},
   "source": [
    "# Visualizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_layers_from_boundary_array(img_array, layer_array, fluid=None):\n",
    "    err_msg = \"layer boundaries not compatible with image width\"\n",
    "    assert img_array.shape[1] == layer_array.shape[0], err_msg\n",
    "    dme_colorcode = {\n",
    "        1: (170, 160, 250),\n",
    "        2: (120, 200, 250),\n",
    "        3: (80, 200, 250),\n",
    "        4: (50, 230, 250),\n",
    "        5: (20, 230, 250),\n",
    "        6: (0, 230, 250),\n",
    "        7: (0, 230, 100),\n",
    "        8: (180, 255, 255)  # fluid\n",
    "    }\n",
    "    amd_colorcode = {\n",
    "        1: (180, 200, 250),\n",
    "        2: (120, 200, 250),\n",
    "    }\n",
    "    zeros = np.zeros_like(img_array, dtype=\"uint8\")\n",
    "    hue = np.zeros_like(img_array, dtype=\"uint8\")\n",
    "    saturation = np.zeros_like(img_array, dtype=\"uint8\")\n",
    "    value = np.zeros_like(img_array, dtype=\"uint8\")\n",
    "    mask = np.zeros(img_array.shape, dtype=\"uint8\")\n",
    "    for w in range(img_array.shape[1]):\n",
    "        if ~np.isnan(layer_array[w, :]).any():\n",
    "            last_boundary = int(layer_array[w, 0])\n",
    "            for idx, h in enumerate(layer_array[w, 1:]):\n",
    "                curr_boundary = int(h) + 1\n",
    "                mask[last_boundary:curr_boundary, w] = idx + 1\n",
    "                last_boundary = curr_boundary\n",
    "    if fluid is not None:\n",
    "        mask[fluid != 0] = 8\n",
    "    if layer_array.shape[1] == 8:\n",
    "        for klass, hsv in dme_colorcode.items():\n",
    "            hue[mask == klass] = hsv[0]\n",
    "            saturation[mask == klass] = hsv[1]\n",
    "            value[mask == klass] = hsv[2]\n",
    "    if layer_array.shape[1] == 3:\n",
    "        for klass, hsv in amd_colorcode.items():\n",
    "            hue[mask == klass] = hsv[0]\n",
    "            saturation[mask == klass] = hsv[1]\n",
    "            value[mask == klass] = hsv[2]\n",
    "    alpha = np.zeros_like(img_array, dtype=\"uint8\")\n",
    "    alpha[mask != 0] = 255\n",
    "    img_stack = np.array([zeros, zeros, img_array]).transpose((1, 2, 0))\n",
    "    img = Image.fromarray(img_stack, mode=\"HSV\")\n",
    "    colored_mask_stack = np.array([hue, saturation, value]).transpose((1, 2, 0))\n",
    "    colored_mask = Image.fromarray(colored_mask_stack, mode=\"HSV\")\n",
    "    alphaimg = Image.fromarray(alpha)\n",
    "    img_with_boundaries = Image.composite(colored_mask, img, alphaimg)\n",
    "    return img_with_boundaries\n",
    "\n",
    "\n",
    "def show_boundary_from_boundary_array(img_array, layer_array):\n",
    "    err_msg = \"layer boundaries not compatible with image width\"\n",
    "    assert img_array.shape[1] == layer_array.shape[0], err_msg\n",
    "    mask = np.zeros(img_array.shape, dtype=\"uint8\")\n",
    "    for w_idx in range(img_array.shape[1]):\n",
    "        if ~np.isnan(layer_array[w_idx, :]).any():\n",
    "            for h_idx in layer_array[w_idx, :]:\n",
    "                mask[int(h_idx), w_idx] = 255\n",
    "    empty = mask.copy()\n",
    "    ones = np.ones(img_array.shape, dtype=\"uint8\") * 255\n",
    "    img_stack = np.array([empty, empty, img_array]).transpose((1, 2, 0))\n",
    "    img = Image.fromarray(img_stack, mode=\"HSV\")\n",
    "    colored_mask_stack = np.array([empty, ones, ones]).transpose((1, 2, 0))\n",
    "    colored_mask = Image.fromarray(colored_mask_stack, mode=\"HSV\")\n",
    "    maskimg = Image.fromarray(mask)\n",
    "    img_with_boundaries = Image.composite(colored_mask, img, maskimg)\n",
    "    return img_with_boundaries\n",
    "\n",
    "\n",
    "def show_layers_from_mask_array(img, mask):\n",
    "    err_msg = \"image and mask do not have the same dimensions\"\n",
    "    assert img.shape == mask.shape, err_msg\n",
    "    dme_colorcode = {\n",
    "        1: (170, 160, 250),\n",
    "        2: (120, 200, 250),\n",
    "        3: (80, 200, 250),\n",
    "        4: (50, 230, 250),\n",
    "        5: (20, 230, 250),\n",
    "        6: (0, 230, 250),\n",
    "        7: (0, 230, 100),\n",
    "        9: (180, 255, 255)  # fluid\n",
    "    }\n",
    "    zeros = np.zeros_like(mask, dtype=\"uint8\")\n",
    "    hue = zeros.copy()\n",
    "    saturation = zeros.copy()\n",
    "    value = zeros.copy()\n",
    "    alpha = zeros.copy()\n",
    "    for klass, hsv in dme_colorcode.items():\n",
    "        hue[mask == klass] = hsv[0]\n",
    "        saturation[mask == klass] = hsv[1]\n",
    "        value[mask == klass] = hsv[2]\n",
    "        alpha[mask == klass] = 255\n",
    "    img_stack = np.array([zeros, zeros, img]).transpose((1, 2, 0))\n",
    "    img_img = Image.fromarray(img_stack, mode=\"HSV\")\n",
    "    colored_mask_stack = np.array([hue, saturation, value]).transpose((1, 2, 0))\n",
    "    mask_img = Image.fromarray(colored_mask_stack, mode=\"HSV\")\n",
    "    alpha_img = Image.fromarray(alpha)\n",
    "    img_w_layers = Image.composite(mask_img, img_img, alpha_img)\n",
    "    return img_w_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345d3601",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d3b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches(img, lyr, patch_width):\n",
    "    idx = np.where((np.isnan(lyr)).any(axis=0))[0]\n",
    "    diff = np.diff(idx)\n",
    "    useful_parts = diff >= patch_width\n",
    "    useful_lengths = diff[useful_parts]\n",
    "    useful_start_idx = idx[np.pad(useful_parts, (0, 1), constant_values=[False])]\n",
    "    for ustart, ulength in zip(useful_start_idx, useful_lengths):\n",
    "        number_of_shifts = (ulength - 1) // patch_width\n",
    "        for shift_idx in range(number_of_shifts):\n",
    "            img_patch = img[:, ustart + 1 + shift_idx * patch_width:ustart + 1 + (shift_idx + 1) * patch_width]\n",
    "            lyr_patch = lyr[:, ustart + 1 + shift_idx * patch_width:ustart + 1 + (shift_idx + 1) * patch_width]\n",
    "            mask = create_layer_mask(lyr_patch, img_patch.shape[0])\n",
    "            yield img_patch, mask\n",
    "            \n",
    "def generate_dme_dataset(input_dir, output_dir, patch_width):\n",
    "    files = list(Path(input_dir).glob(\"*\"))\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir()\n",
    "    cnt = 0\n",
    "    for file in tqdm(files, desc=\"data generation\"):\n",
    "        data = loadmat(file)\n",
    "        layers = data[\"manualLayers1\"].transpose((2, 0, 1))\n",
    "        images = data[\"images\"].transpose((2, 0, 1))\n",
    "        for idx, (image, layer) in enumerate(zip(images, layers)):\n",
    "            patch_generator = create_patches(image, layer, patch_width)\n",
    "            for img, mask in patch_generator:\n",
    "                Image.fromarray(img).save(output_dir / f\"img_{cnt}.png\")\n",
    "                Image.fromarray(mask).save(output_dir / f\"mask_{cnt}.png\")\n",
    "                cnt += 1\n",
    "                \n",
    "def create_boundary_mask(boundary_array, height):\n",
    "    mask = np.zeros((height, boundary_array.shape[1]), dtype=\"uint8\")\n",
    "    for col_idx, col in enumerate(boundary_array.T):\n",
    "        if ~np.isnan(col).any():\n",
    "            for boundary in col:\n",
    "                mask[int(boundary), col_idx] = 1\n",
    "    return mask\n",
    "\n",
    "def create_layer_mask(boundary_array, height):\n",
    "    mask = np.zeros((height, boundary_array.shape[1]), dtype=\"uint8\")\n",
    "    for col_idx, col in enumerate(boundary_array.T):\n",
    "        prev_boundary = 0\n",
    "        for boundary_idx, boundary in enumerate(col):\n",
    "            mask[prev_boundary:int(boundary) + 1, col_idx] = boundary_idx\n",
    "            prev_boundary = int(boundary) + 1\n",
    "        mask[prev_boundary:, col_idx] = boundary_idx + 1\n",
    "    return mask\n",
    "\n",
    "def create_patches(img, lyr, patch_width):\n",
    "    idx = np.where((np.isnan(lyr)).any(axis=0))[0]\n",
    "    diff = np.diff(idx)\n",
    "    useful_parts = diff >= patch_width\n",
    "    useful_lengths = diff[useful_parts]\n",
    "    useful_start_idx = idx[np.pad(useful_parts, (0, 1), constant_values=[False])]\n",
    "    for ustart, ulength in zip(useful_start_idx, useful_lengths):\n",
    "        number_of_shifts = (ulength - 1) // patch_width\n",
    "        for shift_idx in range(number_of_shifts):\n",
    "            img_patch = img[:, ustart + 1 + shift_idx * patch_width:ustart + 1 + (shift_idx + 1) * patch_width]\n",
    "            lyr_patch = lyr[:, ustart + 1 + shift_idx * patch_width:ustart + 1 + (shift_idx + 1) * patch_width]\n",
    "#             lyr_patch_padded = np.pad(lyr, ((0, 1), (0, 0)), constant_values=(495,))\n",
    "#             lyr_patch_padded = np.pad(lyr_patch_padded, ((1, 0), (0, 0)), constant_values=(0,))\n",
    "#             lyr_patch_widths = np.diff(lyr_patch_padded)\n",
    "            mask = create_layer_mask(lyr_patch, img_patch.shape[0])\n",
    "            yield img_patch, mask, lyr_patch.T.tolist()#, lyr_patch_widths.T.tolist()\n",
    "            \n",
    "def generate_dme_dataset(input_dir, output_dir, patch_width):\n",
    "    files = list(Path(input_dir).glob(\"*\"))\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir()\n",
    "    cnt = 0\n",
    "    boundary_indices_dict = {}\n",
    "    layer_widths_dict = {}\n",
    "    for file in tqdm(files, desc=\"data generation\"):\n",
    "        data = loadmat(file)\n",
    "        layers = data[\"manualLayers1\"].transpose((2, 0, 1))\n",
    "        images = data[\"images\"].transpose((2, 0, 1))\n",
    "        for idx, (image, layer) in enumerate(zip(images, layers)):\n",
    "            patch_generator = create_patches(image, layer, patch_width)\n",
    "            for img, mask, boundary_indices_list, layer_widths_list in patch_generator:\n",
    "                Image.fromarray(img).save(output_dir / f\"img_{cnt}.png\")\n",
    "                Image.fromarray(mask).save(output_dir / f\"mask_{cnt}.png\")\n",
    "                boundary_indices_dict[cnt] = boundary_indices_list\n",
    "                layer_widths_dict[cnt] = layer_widths_list\n",
    "                cnt += 1\n",
    "    with open(output_dir / \"boundary_indices.json\", \"w\") as boundary_file:\n",
    "        json.dump(boundary_indices_dict, boundary_file)\n",
    "#     with open(output_dir / \"layer_widths.json\", \"w\") as layer_widths_file:\n",
    "#         json.dump(layer_widths_dict, layer_widths_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0feeaf",
   "metadata": {},
   "source": [
    "# LOAD FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2c17a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "amd = list(Path(\"../../dataset/raw/AMD/\").glob(\"*\"))\n",
    "control = list(Path(\"../../dataset/raw/Control/\").glob(\"*\"))\n",
    "dme = list(Path(\"../../dataset/raw/2015_BOE_Chiu/\").glob(\"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8709a66a",
   "metadata": {},
   "source": [
    "# Test new concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d8a401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee866709",
   "metadata": {},
   "source": [
    "# DME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ae34680",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(dme[2])\n",
    "idx = 35\n",
    "img = data[\"images\"][:, :, idx]\n",
    "lyr = data[\"manualLayers1\"][:, :, idx]\n",
    "lyr2 = data[\"manualLayers2\"][:, :, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f519d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_layers_from_mask_array(img, mask):\n",
    "    err_msg = \"image and mask do not have the same dimensions\"\n",
    "    assert img.shape == mask.shape, err_msg\n",
    "    dme_colorcode = {\n",
    "        1: (170, 160, 250),\n",
    "        2: (120, 200, 250),\n",
    "        3: (80, 200, 250),\n",
    "        4: (50, 230, 250),\n",
    "        5: (20, 230, 250),\n",
    "        6: (0, 230, 250),\n",
    "        7: (0, 230, 100),\n",
    "        9: (180, 255, 255)  # fluid\n",
    "    }\n",
    "    zeros = np.zeros_like(mask, dtype=\"uint8\")\n",
    "    hue = zeros.copy()\n",
    "    saturation = zeros.copy()\n",
    "    value = zeros.copy()\n",
    "    alpha = zeros.copy()\n",
    "    for klass, hsv in dme_colorcode.items():\n",
    "        hue[mask == klass] = hsv[0]\n",
    "        saturation[mask == klass] = hsv[1]\n",
    "        value[mask == klass] = hsv[2]\n",
    "        alpha[mask == klass] = 200\n",
    "    img_stack = np.array([zeros, zeros, img]).transpose((1, 2, 0))\n",
    "    img_img = Image.fromarray(img_stack, mode=\"HSV\")\n",
    "    colored_mask_stack = np.array([hue, saturation, value]).transpose((1, 2, 0))\n",
    "    mask_img = Image.fromarray(colored_mask_stack, mode=\"HSV\")\n",
    "    alpha_img = Image.fromarray(alpha)\n",
    "    img_w_layers = Image.composite(mask_img, img_img, alpha_img)\n",
    "    return img_w_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bdf5a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 12\n",
    "img = np.array(Image.open(f\"../../generated/DME_496/img_{idx}.png\"))\n",
    "lyr = np.array(Image.open(f\"../../generated/DME_496/mask_{idx}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db7cee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_mask_array(img, lyr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73e451ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_boundary_array(img, lyr2.T).show()\n",
    "show_layers_from_boundary_array(img, lyr.T).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "1881425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(\"../../dataset/raw/2015_BOE_Chiu/Subject_02.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "03a4bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "8b008a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data[\"images\"][..., idx]\n",
    "lyr = data[\"manualLayers1\"][..., idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "47facfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_boundary_array(img, lyr.T).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9367ecce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(523, 523): 33,\n",
       "         (547, 547): 11,\n",
       "         (535, 535): 11,\n",
       "         (541, 541): 33,\n",
       "         (505, 505): 11,\n",
       "         (499, 499): 11})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmented_length = list()\n",
    "\n",
    "for d in range(10):\n",
    "    data = loadmat(dme[d])\n",
    "    for lyr_ind in range(61):\n",
    "        m1 = data[\"manualLayers1\"][..., lyr_ind]\n",
    "        m2 = data[\"manualLayers2\"][..., lyr_ind]\n",
    "        lengths = [] \n",
    "        if (~np.isnan(m1)).any():\n",
    "            w_idx = np.where(~np.isnan(m1))[1]\n",
    "            delta = w_idx[-1] - w_idx[0]\n",
    "            lengths.append(delta)\n",
    "        else:\n",
    "            lengths.append(0)\n",
    "        if (~np.isnan(m2)).any():\n",
    "            w_idx = np.where(~np.isnan(m2))[1]\n",
    "            delta = w_idx[-1] - w_idx[0]\n",
    "            lengths.append(delta)\n",
    "        else:\n",
    "            lengths.append(0)\n",
    "        if sum(lengths):\n",
    "            segmented_length.append(tuple(lengths))\n",
    "            \n",
    "Counter(segmented_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec83def",
   "metadata": {},
   "outputs": [],
   "source": [
    "dme496img = sorted(list(Path(\"../../generated/DME_496/\").glob(\"img*\")))\n",
    "dme496mask = sorted(list(Path(\"../../generated/DME_496\").glob(\"mask*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21eae840",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open(dme496img[0]))\n",
    "mask = np.array(Image.open(dme496mask[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbc01dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_mask_array(img, mask).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570cfe54",
   "metadata": {},
   "source": [
    "# There are parts where not all the layers are annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73888515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0, 127,   0,   0,   0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for d in range(10):\n",
    "#     data = loadmat(dme[d])\n",
    "#     lyr = data[\"manualLayers1\"]\n",
    "#     if (np.isnan(lyr).any(axis=0) != np.isnan(lyr).all(axis=0)).sum():\n",
    "#         print(d)\n",
    "\n",
    "data = loadmat(dme[0])\n",
    "lyr = data[\"manualLayers1\"]\n",
    "img = data[\"images\"]\n",
    "idx = (np.isnan(lyr).any(axis=0) != np.isnan(lyr).all(axis=0))\n",
    "np.isnan(lyr[:, idx]).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e644668d",
   "metadata": {},
   "source": [
    "# Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fda3d1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data generation: 100%|██████████| 10/10 [00:19<00:00,  1.95s/it]\n"
     ]
    }
   ],
   "source": [
    "patch_width = 70\n",
    "generate_dme_dataset(\"../../dataset/raw/2015_BOE_Chiu\", f\"../../generated/DME_{patch_width}\", patch_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9c6b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "954"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(Path(f\"../../generated/DME_{patch_width}\").glob(\"img*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a386ab56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 768, 61)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b37cc",
   "metadata": {},
   "source": [
    "# Proove that the layer mask generation is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "0ddb5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmask = create_boundary_mask(lyr[:, 500:600], 496)\n",
    "lmask = create_layer_mask(lyr[:, 500:600], 496)\n",
    "diff = np.diff(lmask, axis=0)\n",
    "(np.pad(diff, ((0, 1), (0, 0)), constant_values=(0,)) != bmask).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac80d068",
   "metadata": {},
   "source": [
    "# AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69b56226",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(amd[0])\n",
    "idx = 30\n",
    "img = data[\"images\"][:, :, idx]\n",
    "lyr = data[\"layerMaps\"][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0840380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_amd_dataset(amd_dir, control_dir, output_dir, patch_width):\n",
    "    files = list(\n",
    "        chain(\n",
    "            Path(amd_dir).glob(\"*\"),\n",
    "            Path(control_dir).glob(\"*\")\n",
    "        )\n",
    "    )\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir()\n",
    "    cnt = 0\n",
    "    for file in tqdm(files, desc=\"data generation\"):\n",
    "        data = loadmat(file)\n",
    "        layers = data[\"layerMaps\"].transpose((0, 2, 1))\n",
    "        images = data[\"images\"].transpose((2, 0, 1))\n",
    "        for idx, (image, layer) in enumerate(zip(images, layers)):\n",
    "            patch_generator = create_patches(image, layer, patch_width)\n",
    "            for img, mask in patch_generator:\n",
    "                Image.fromarray(img).save(output_dir / f\"img_{cnt}.png\")\n",
    "                Image.fromarray(mask).save(output_dir / f\"mask_{cnt}.png\")\n",
    "                cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d54746e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data generation: 100%|██████████| 384/384 [04:31<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "patch_width = 736\n",
    "generate_amd_dataset(\n",
    "    \"../../dataset/raw/AMD/\",\n",
    "    \"../../dataset/raw/Control/\",\n",
    "    f\"../../generated/AMD_{patch_width}\",\n",
    "    patch_width\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b0c75ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2901"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(Path(\"../../generated/AMD_736\").glob(\"img*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0e46613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadmat(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2598c36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "736 / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebf054f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_layers_from_boundary_array(img, lyr).show()\n",
    "show_boundary_from_boundary_array(img, lyr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb3594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
